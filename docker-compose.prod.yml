version: '3.8'

# Production environment Docker Compose override
services:
  # MongoDB with production settings
  mongodb:
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    command: mongod --auth --bind_ip_all --replSet rs0 --wiredTigerCacheSizeGB 0.5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis with production settings
  redis:
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 256mb --maxmemory-policy allkeys-lru --save 900 1 --save 300 10 --save 60 10000
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Backend with production scaling
  backend:
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    environment:
      NODE_ENV: production
      LOG_LEVEL: warn
      CLUSTER_MODE: enabled
      MAX_OLD_SPACE_SIZE: 896

  # Flask AI with production scaling
  flask-ai:
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    environment:
      FLASK_ENV: production
      FLASK_DEBUG: 0
      LOG_LEVEL: WARNING
      GUNICORN_WORKERS: 4
      GUNICORN_TIMEOUT: 120

  # Frontend with production optimizations
  frontend:
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  # Nginx Load Balancer for production
  nginx:
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # Log aggregation service
  fluentd:
    image: fluent/fluentd:v1.16-debian-1
    container_name: teachai-fluentd
    restart: unless-stopped
    volumes:
      - ./docker/fluentd.conf:/fluentd/etc/fluent.conf:ro
      - backend_logs:/var/log/backend:ro
      - flask_logs:/var/log/flask:ro
      - nginx_logs:/var/log/nginx:ro
    networks:
      - teachai-network
    profiles:
      - logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Monitoring service
  prometheus:
    image: prom/prometheus:latest
    container_name: teachai-prometheus
    restart: unless-stopped
    volumes:
      - ./docker/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - teachai-network
    profiles:
      - monitoring
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=30d'

  # Grafana for monitoring dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: teachai-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin123}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana:/etc/grafana/provisioning
    ports:
      - "3001:3000"
    networks:
      - teachai-network
    depends_on:
      - prometheus
    profiles:
      - monitoring

volumes:
  prometheus_data:
    driver: local
  grafana_data:
    driver: local